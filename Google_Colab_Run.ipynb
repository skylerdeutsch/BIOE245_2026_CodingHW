{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOWGD9oH/UP1zS3DG2YUDjS"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "NXuFULpwHGNu",
        "outputId": "78dd3025-4d6d-4d60-d05f-dd1444058f1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: medmnist in /usr/local/lib/python3.12/dist-packages (3.0.2)\n",
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.12/dist-packages (2.6.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from medmnist) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from medmnist) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from medmnist) (1.6.1)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.12/dist-packages (from medmnist) (0.25.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from medmnist) (4.67.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from medmnist) (11.3.0)\n",
            "Requirement already satisfied: fire in /usr/local/lib/python3.12/dist-packages (from medmnist) (0.7.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from medmnist) (2.10.0+cu128)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from medmnist) (0.25.0+cu128)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorboardX) (26.0)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.12/dist-packages (from tensorboardX) (5.29.6)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.12/dist-packages (from fire->medmnist) (3.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->medmnist) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->medmnist) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->medmnist) (2025.3)\n",
            "Requirement already satisfied: scipy>=1.11.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image->medmnist) (1.16.3)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from scikit-image->medmnist) (3.6.1)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.12/dist-packages (from scikit-image->medmnist) (2.37.2)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image->medmnist) (2026.2.16)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image->medmnist) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->medmnist) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->medmnist) (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (3.24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (1.14.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (2025.3.0)\n",
            "Requirement already satisfied: cuda-bindings==12.9.4 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (12.9.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (12.8.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (11.3.3.83)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (10.3.9.90)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (11.7.3.90)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (12.5.8.93)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.4.5 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (3.4.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (12.8.90)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (1.13.1.3)\n",
            "Requirement already satisfied: triton==3.6.0 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (3.6.0)\n",
            "Requirement already satisfied: cuda-pathfinder~=1.1 in /usr/local/lib/python3.12/dist-packages (from cuda-bindings==12.9.4->torch->medmnist) (1.3.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->medmnist) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->medmnist) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->medmnist) (3.0.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install medmnist tensorboardX"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# Script\n",
        "import argparse\n",
        "import os\n",
        "import time\n",
        "from collections import OrderedDict\n",
        "\n",
        "import argparse\n",
        "import os\n",
        "import time\n",
        "from collections import OrderedDict\n",
        "from copy import deepcopy\n",
        "\n",
        "import medmnist\n",
        "import numpy as np\n",
        "import PIL\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import torchvision.transforms as transforms\n",
        "from medmnist import INFO, Evaluator\n",
        "from models import ResNet18, ResNet50\n",
        "from tensorboardX import SummaryWriter\n",
        "from torchvision.models import resnet18, resnet50\n",
        "from tqdm import trange\n",
        "\n",
        "\n",
        "def main(data_flag, output_root, num_epochs, gpu_ids, batch_size,\n",
        "         size, download, model_flag, resize, as_rgb, model_path, run, dataset_root=None):\n",
        "\n",
        "    lr = 0.001\n",
        "    gamma=0.1\n",
        "    milestones = [0.5 * num_epochs, 0.75 * num_epochs]\n",
        "\n",
        "    info = INFO[data_flag]\n",
        "    task = info['task']\n",
        "    n_channels = 3 if as_rgb else info['n_channels']\n",
        "    n_classes = len(info['label'])\n",
        "\n",
        "    DataClass = getattr(medmnist, info['python_class'])\n",
        "\n",
        "    str_ids = gpu_ids.split(',')\n",
        "    gpu_ids = []\n",
        "    for str_id in str_ids:\n",
        "        id = int(str_id)\n",
        "        if id >= 0:\n",
        "            gpu_ids.append(id)\n",
        "\n",
        "    if len(gpu_ids) > 0:\n",
        "        os.environ[\"CUDA_VISIBLE_DEVICES\"]=str(gpu_ids[0])\n",
        "        device = torch.device('cuda:0')\n",
        "    else:\n",
        "        device = torch.device('cpu')\n",
        "\n",
        "    output_root = os.path.join(output_root, data_flag, time.strftime(\"%y%m%d_%H%M%S\"))\n",
        "    if not os.path.exists(output_root):\n",
        "        os.makedirs(output_root)\n",
        "\n",
        "    print('==> Preparing data...')\n",
        "\n",
        "    if resize:\n",
        "        data_transform = transforms.Compose(\n",
        "            [transforms.Resize((224, 224), interpolation=PIL.Image.NEAREST),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[.5], std=[.5])])\n",
        "    else:\n",
        "        data_transform = transforms.Compose(\n",
        "            [transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[.5], std=[.5])])\n",
        "\n",
        "    if dataset_root is None:\n",
        "        train_dataset = DataClass(split='train', transform=data_transform, download=download, as_rgb=as_rgb, size=size)\n",
        "        val_dataset = DataClass(split='val', transform=data_transform, download=download, as_rgb=as_rgb, size=size)\n",
        "        test_dataset = DataClass(split='test', transform=data_transform, download=download, as_rgb=as_rgb, size=size)\n",
        "    else:\n",
        "        train_dataset = DataClass(split='train', transform=data_transform, download=download,\n",
        "            as_rgb=as_rgb, root=dataset_root, size=size)\n",
        "        val_dataset = DataClass(split='val', transform=data_transform, download=download,\n",
        "            as_rgb=as_rgb, root=dataset_root, size=size)\n",
        "        test_dataset = DataClass(split='test', transform=data_transform, download=download,\n",
        "            as_rgb=as_rgb, root=dataset_root, size=size)\n",
        "\n",
        "    train_loader = data.DataLoader(dataset=train_dataset,\n",
        "                                batch_size=batch_size,\n",
        "                                shuffle=True)\n",
        "    train_loader_at_eval = data.DataLoader(dataset=train_dataset,\n",
        "                                batch_size=batch_size,\n",
        "                                shuffle=False)\n",
        "    val_loader = data.DataLoader(dataset=val_dataset,\n",
        "                                batch_size=batch_size,\n",
        "                                shuffle=False)\n",
        "    test_loader = data.DataLoader(dataset=test_dataset,\n",
        "                                batch_size=batch_size,\n",
        "                                shuffle=False)\n",
        "\n",
        "    print('==> Building and training model...')\n",
        "\n",
        "\n",
        "    if model_flag == 'resnet18':\n",
        "        model =  resnet18(pretrained=False, num_classes=n_classes) if resize else ResNet18(in_channels=n_channels, num_classes=n_classes)\n",
        "    elif model_flag == 'resnet50':\n",
        "        model =  resnet50(pretrained=False, num_classes=n_classes) if resize else ResNet50(in_channels=n_channels, num_classes=n_classes)\n",
        "    else:\n",
        "        raise NotImplementedError\n",
        "\n",
        "    model = model.to(device)\n",
        "\n",
        "    if dataset_root is None:\n",
        "        train_evaluator = medmnist.Evaluator(data_flag, 'train', size=size)\n",
        "        val_evaluator = medmnist.Evaluator(data_flag, 'val', size=size)\n",
        "        test_evaluator = medmnist.Evaluator(data_flag, 'test', size=size)\n",
        "    else:\n",
        "        train_evaluator = medmnist.Evaluator(data_flag, 'train', size=size, root=dataset_root)\n",
        "        val_evaluator = medmnist.Evaluator(data_flag, 'val', size=size, root=dataset_root)\n",
        "        test_evaluator = medmnist.Evaluator(data_flag, 'test', size=size, root=dataset_root)\n",
        "\n",
        "    if task == \"multi-label, binary-class\":\n",
        "        criterion = nn.BCEWithLogitsLoss()\n",
        "    else:\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    if model_path is not None:\n",
        "        model.load_state_dict(torch.load(model_path, map_location=device)['net'], strict=True)\n",
        "        train_metrics = test(model, train_evaluator, train_loader_at_eval, task, criterion, device, run, output_root)\n",
        "        val_metrics = test(model, val_evaluator, val_loader, task, criterion, device, run, output_root)\n",
        "        test_metrics = test(model, test_evaluator, test_loader, task, criterion, device, run, output_root)\n",
        "\n",
        "        print('train  auc: %.5f  acc: %.5f\\n' % (train_metrics[1], train_metrics[2]) + \\\n",
        "              'val  auc: %.5f  acc: %.5f\\n' % (val_metrics[1], val_metrics[2]) + \\\n",
        "              'test  auc: %.5f  acc: %.5f\\n' % (test_metrics[1], test_metrics[2]))\n",
        "\n",
        "    if num_epochs == 0:\n",
        "        return\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=milestones, gamma=gamma)\n",
        "\n",
        "    logs = ['loss', 'auc', 'acc']\n",
        "    train_logs = ['train_'+log for log in logs]\n",
        "    val_logs = ['val_'+log for log in logs]\n",
        "    test_logs = ['test_'+log for log in logs]\n",
        "    log_dict = OrderedDict.fromkeys(train_logs+val_logs+test_logs, 0)\n",
        "\n",
        "    writer = SummaryWriter(log_dir=os.path.join(output_root, 'Tensorboard_Results'))\n",
        "\n",
        "    best_auc = 0\n",
        "    best_epoch = 0\n",
        "    best_model = deepcopy(model)\n",
        "\n",
        "    global iteration\n",
        "    iteration = 0\n",
        "\n",
        "    for epoch in trange(num_epochs):\n",
        "        train_loss = train(model, train_loader, task, criterion, optimizer, device, writer)\n",
        "\n",
        "        train_metrics = test(model, train_evaluator, train_loader_at_eval, task, criterion, device, run)\n",
        "        val_metrics = test(model, val_evaluator, val_loader, task, criterion, device, run)\n",
        "        test_metrics = test(model, test_evaluator, test_loader, task, criterion, device, run)\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        for i, key in enumerate(train_logs):\n",
        "            log_dict[key] = train_metrics[i]\n",
        "        for i, key in enumerate(val_logs):\n",
        "            log_dict[key] = val_metrics[i]\n",
        "        for i, key in enumerate(test_logs):\n",
        "            log_dict[key] = test_metrics[i]\n",
        "\n",
        "        for key, value in log_dict.items():\n",
        "            writer.add_scalar(key, value, epoch)\n",
        "\n",
        "        cur_auc = val_metrics[1]\n",
        "        if cur_auc > best_auc:\n",
        "            best_epoch = epoch\n",
        "            best_auc = cur_auc\n",
        "            best_model = deepcopy(model)\n",
        "            print('cur_best_auc:', best_auc)\n",
        "            print('cur_best_epoch', best_epoch)\n",
        "\n",
        "    state = {\n",
        "        'net': best_model.state_dict(),\n",
        "    }\n",
        "\n",
        "    path = os.path.join(output_root, 'best_model.pth')\n",
        "    torch.save(state, path)\n",
        "\n",
        "    train_metrics = test(best_model, train_evaluator, train_loader_at_eval, task, criterion, device, run, output_root)\n",
        "    val_metrics = test(best_model, val_evaluator, val_loader, task, criterion, device, run, output_root)\n",
        "    test_metrics = test(best_model, test_evaluator, test_loader, task, criterion, device, run, output_root)\n",
        "\n",
        "    train_log = 'train  auc: %.5f  acc: %.5f\\n' % (train_metrics[1], train_metrics[2])\n",
        "    val_log = 'val  auc: %.5f  acc: %.5f\\n' % (val_metrics[1], val_metrics[2])\n",
        "    test_log = 'test  auc: %.5f  acc: %.5f\\n' % (test_metrics[1], test_metrics[2])\n",
        "\n",
        "    log = '%s\\n' % (data_flag) + train_log + val_log + test_log\n",
        "    print(log)\n",
        "\n",
        "    with open(os.path.join(output_root, '%s_log.txt' % (data_flag)), 'a') as f:\n",
        "        f.write(log)\n",
        "\n",
        "    writer.close()\n",
        "\n",
        "\n",
        "def train(model, train_loader, task, criterion, optimizer, device, writer):\n",
        "    total_loss = []\n",
        "    global iteration\n",
        "\n",
        "    model.train()\n",
        "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs.to(device))\n",
        "\n",
        "        if task == 'multi-label, binary-class':\n",
        "            targets = targets.to(torch.float32).to(device)\n",
        "            loss = criterion(outputs, targets)\n",
        "        else:\n",
        "            targets = torch.squeeze(targets, 1).long().to(device)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "        total_loss.append(loss.item())\n",
        "        writer.add_scalar('train_loss_logs', loss.item(), iteration)\n",
        "        iteration += 1\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    epoch_loss = sum(total_loss)/len(total_loss)\n",
        "    return epoch_loss\n",
        "\n",
        "\n",
        "def test(model, evaluator, data_loader, task, criterion, device, run, save_folder=None):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    total_loss = []\n",
        "    y_score = torch.tensor([]).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(data_loader):\n",
        "            outputs = model(inputs.to(device))\n",
        "\n",
        "            if task == 'multi-label, binary-class':\n",
        "                targets = targets.to(torch.float32).to(device)\n",
        "                loss = criterion(outputs, targets)\n",
        "                m = nn.Sigmoid()\n",
        "                outputs = m(outputs).to(device)\n",
        "            else:\n",
        "                targets = torch.squeeze(targets, 1).long().to(device)\n",
        "                loss = criterion(outputs, targets)\n",
        "                m = nn.Softmax(dim=1)\n",
        "                outputs = m(outputs).to(device)\n",
        "                targets = targets.float().resize_(len(targets), 1)\n",
        "\n",
        "            total_loss.append(loss.item())\n",
        "            y_score = torch.cat((y_score, outputs), 0)\n",
        "\n",
        "        y_score = y_score.detach().cpu().numpy()\n",
        "        auc, acc = evaluator.evaluate(y_score, save_folder, run)\n",
        "\n",
        "        test_loss = sum(total_loss) / len(total_loss)\n",
        "\n",
        "        return [test_loss, auc, acc]\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    parser = argparse.ArgumentParser(\n",
        "        description='RUN Baseline model of MedMNIST2D')\n",
        "\n",
        "    parser.add_argument('--data_flag',\n",
        "                        default='pathmnist',\n",
        "                        type=str)\n",
        "    parser.add_argument('--output_root',\n",
        "                        default='./output',\n",
        "                        help='output root, where to save models and results',\n",
        "                        type=str)\n",
        "    parser.add_argument('--num_epochs',\n",
        "                        default=100,\n",
        "                        help='num of epochs of training, the script would only test model if set num_epochs to 0',\n",
        "                        type=int)\n",
        "    parser.add_argument('--size',\n",
        "                        default=28,\n",
        "                        help='the image size of the dataset, 28 or 64 or 128 or 224, default=28',\n",
        "                        type=int)\n",
        "    parser.add_argument('--gpu_ids',\n",
        "                        default='0',\n",
        "                        type=str)\n",
        "    parser.add_argument('--batch_size',\n",
        "                        default=128,\n",
        "                        type=int)\n",
        "    parser.add_argument('--download',\n",
        "                        action=\"store_true\")\n",
        "    parser.add_argument('--resize',\n",
        "                        help='resize images of size 28x28 to 224x224',\n",
        "                        action=\"store_true\")\n",
        "    parser.add_argument('--as_rgb',\n",
        "                        help='convert the grayscale image to RGB',\n",
        "                        action=\"store_true\")\n",
        "    parser.add_argument('--model_path',\n",
        "                        default=None,\n",
        "                        help='root of the pretrained model to test',\n",
        "                        type=str)\n",
        "    parser.add_argument('--model_flag',\n",
        "                        default='resnet18',\n",
        "                        help='choose backbone from resnet18, resnet50',\n",
        "                        type=str)\n",
        "    parser.add_argument('--run',\n",
        "                        default='model1',\n",
        "                        help='to name a standard evaluation csv file, named as {flag}_{split}_[AUC]{auc:.3f}_[ACC]{acc:.3f}@{run}.csv',\n",
        "                        type=str)\n",
        "    parser.add_argument('--dataset_root',\n",
        "                        default=None,\n",
        "                        help='the root folder of the dataset',\n",
        "                        type=str)\n",
        "\n",
        "\n",
        "    args = parser.parse_args()\n",
        "    data_flag = args.data_flag\n",
        "    output_root = args.output_root\n",
        "    num_epochs = args.num_epochs\n",
        "    size = args.size\n",
        "    gpu_ids = args.gpu_ids\n",
        "    batch_size = args.batch_size\n",
        "    download = args.download\n",
        "    model_flag = args.model_flag\n",
        "    resize = args.resize\n",
        "    as_rgb = args.as_rgb\n",
        "    model_path = args.model_path\n",
        "    run = args.run\n",
        "    dataset_root = args.dataset_root\n",
        "\n",
        "    if dataset_root is not None and not os.path.isdir(dataset_root):\n",
        "        os.makedirs(dataset_root)\n",
        "\n",
        "    main(data_flag, output_root, num_epochs, gpu_ids, batch_size,\n",
        "        size, download, model_flag, resize, as_rgb, model_path, run, dataset_root)"
      ],
      "metadata": {
        "id": "HBfCWbDnI1ea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/MedMNIST/experiments/main/MedMNIST2D/models.py"
      ],
      "metadata": {
        "id": "BVbR0a7hIJMT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python train_and_eval.py \\\n",
        "  --download \\\n",
        "  --output_root \"./output\" \\\n",
        "  --gpu_ids \"0\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nKVK6x2cIRXO",
        "outputId": "5a01c38b-571a-4dc4-b922-b668d810dff5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Preparing data...\n",
            "100% 206M/206M [00:17<00:00, 11.8MB/s]\n",
            "==> Building and training model...\n",
            "  0% 0/100 [00:00<?, ?it/s]cur_best_auc: 0.9859684801302391\n",
            "cur_best_epoch 0\n",
            "  1% 1/100 [01:47<2:57:32, 107.60s/it]cur_best_auc: 0.9904381440067878\n",
            "cur_best_epoch 1\n",
            "  2% 2/100 [03:41<3:02:10, 111.54s/it]cur_best_auc: 0.9959986898142046\n",
            "cur_best_epoch 2\n",
            "  3% 3/100 [05:35<3:01:46, 112.44s/it]"
          ]
        }
      ]
    }
  ]
}