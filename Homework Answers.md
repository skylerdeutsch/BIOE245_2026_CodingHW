## Task 2: Training Configuration Analysis
Answer the following questions about the training setup:

**Q1. What learning rates are used in the training?**

A: 

**Q2. What is the train/val/test split of the dataset (provide sample counts)?**

A:

**Q3. What are the dimensions of the model input per batch?**

A:

**Q4. What is the dimension of the model output during training? What does it represent?**

A:

**Q5. What type of task is this? What loss function is used?**

A:

**Q6. How many files are generated after training? Where are they located and what do they contain?**

A:


## Task 3: Training Statistics Visualization
Examine the training statistics and answer the following questions. Include screenshots of the curves to support your answers.

**Q1. Where are the training statistics stored? Demonstrate how to visualize them.**

A:

**Q2. How many curves are displayed? What do they represent and how are they calculated?**

A:

**Q3. How does the learning rate schedule correlate with the behavior of the curves?**

A:

**Q4. What observations can you make about the curve trends? Are they monotonically increasing, decreasing, or fluctuating? Explain why.**

A:

## Task 4: AUC Metric Analysis

According to this [Google ML Glossary post](link), AUC (Area Under Curve) is a metric between 0.0 and 1.0 that represents a binary classification model's ability to separate positive classes from negative classes.

**1. Is AUC used in this training script? If so, is it applied directly for binary classification, or are there adaptations for multi-class classification?**

A:

**2. What curve does "AUC" refer to? Plot this curve for the saved model evaluated on the test set.**

A:

**3. From the test set, find examples for 5 classes of your choice:**
- One example where the model correctly predicts the class
- One example where the model incorrectly predicts the class

Include the images in your report (total: 10 images).

A:
